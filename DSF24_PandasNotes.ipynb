{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Basics\n",
    "Pandas is another important library in the data science world. It is the standard for manipulating multidimensional data in an efficient way using Python and has many powerful routines we will use to investigate and manipulate data sets.\n",
    "\n",
    "### Resources\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/reference/index.html)\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html)\n",
    "- [Pandas Basics Notes](https://github.com/richardfoltyn/python-statistics/blob/main/latex/unit08.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas?\n",
    "\n",
    "Pandas is a newer package built on top of NumPy, and provides an efficient implementation of a `DataFrame`. `DataFrames` are essentially multidimensional arrays with attached row and column labels that can handle multiple data types and/or missing data. Pandas also defines `Series` which represents observations of a single variable. Not only is Pandas is a convenient medium for storing labeled data, it implements many powerful operations from database managers and spreadsheet programs.\n",
    " \n",
    "Pandas was created to offer more versatile data structures that are straightforward to use for storing, manipulating and analyzing heterogeneous data:\n",
    "1. Data is clearly organized in *variables* and *observations*\n",
    "2. Each variable is permitted to have a different data type.\n",
    "3. We can use *labels* to select observations, instead of having to use a linear numerical index as with NumPy. We could, for example, index a data set using National Insurance Numbers.\n",
    "4. Pandas offers many convenient data aggregation and reduction routines that can be applied to subsets of data. For example, we can easily group observations by city and compute average incomes.\n",
    "5. Pandas also offers many convenient data import / export functions that go beyond whatâ€™s in NumPy.\n",
    "\n",
    "Then shouldn't we be using pandas at all times, then? No!\n",
    "- For low-level tasks where performance is essential, use NumPy.\n",
    "- For homogenous data without any particular data structure, use NumPy.\n",
    "- On the other hand, if data is heterogeneous, needs to be imported from an external data source and cleaned or transformed before performing computations, use pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pandas\n",
    "Pandas has two main data structures:\n",
    "1. `Series` represents observations of a single variable.\n",
    "2. `DataFrame` is a container for several variables. You can think of each individual column of a `DataFrame` as a `Series`, and each row represents one observation.\n",
    "\n",
    "\n",
    "The easiest way to create a `Series` or `DataFrame` is to create them from pre-existing data.\n",
    "To access pandas data structures and routines, we need to import them first. The near-universal\n",
    "convention is to make pandas available using the name `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series object\n",
    "A Pandas `Series` is a one-dimensional array of indexed data. It can be created from a list or array as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `Series` object is a combination of a sequence of values and a sequence of indicies, which we can access with the `values` and `index` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `index` is an array-like object of type `pd.Index`, which we'll discuss in more detail later.\n",
    "\n",
    "We can access elements in a `Series` the same way as regular Python lists with the familiar squarebracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing works the same as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, a `Series` object may seem basically interchangable with a NumPy array or a Python list.\n",
    "\n",
    "The essential difference is the presence of the index: while the NumPy array has an *implicitly defined* integer index used to access the values, the pandas `Series` has an *explicitly defined* index associated with the values.\n",
    "\n",
    "This explicit index definition gives the `Series` object additional capabilities. For example, the index doesn't need to be an integer, but can consist of values of any desired type. For example, if we wish, we can use strings as an indicies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can access the elements the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use non-contiguous or non-sequential indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, you can think of a pandas `Series` a bit like a specialization of a Python dictionary. \n",
    "- A dictionary is a structure that maps arbitrary keys to a set of arbitrary values\n",
    "- A `Series` is a structure which maps typed keys to a set of typed values.\n",
    "\n",
    "This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a pandas `Series` makes it much more efficient than Python dictionaries for certain operations.\n",
    "\n",
    "The `Series`-as-dictionary analogy can be made even more clear by constructing a `Series` object directly from a Python dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,'Texas': 26448193,'New York': 19651127,'Florida': 19552860,'Illinois': 12882135}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though unlike a dictionary, the `Series` also supports array-style operations such as slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame object\n",
    "We can create a `DataFrame` from a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.random.randint(10, size=(10,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also recreate our data table from earlier with multiple data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data types differ across columns, as in the above example, it is often convenient to create the\n",
    "`DataFrame` by passing a dictionary as an argument. Each key represents a column name and each\n",
    "corresponding value contains the data for that variable. This is also often eaiser than adding columns separately.\n",
    "\n",
    "You can also create `DataFrames` from one of more `Series` objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                  'New York': 141297, 'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                 'New York': 19651127, 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will primarily be populating our `DataFrames` by reading in `.csv` files as you will see in the next section. Pandas also has support for creating `DataFrames` from other standard formats like JSON and XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing data\n",
    "With large data sets, you hardly ever want to print the entire `DataFrame`. Pandas by default limits the\n",
    "amount of data shown. You can use the `head()` and `tail()` methods to explicitly display a specific\n",
    "number of rows from the top or the end of a `DataFrame`.\n",
    "\n",
    "To illustrate, we use a data set of 23 UK universities that contains the following variables:\n",
    "- `Instititution`: Name of the institution\n",
    "- `Country`: Country/nation within the UK (England, Scotland, . . . )\n",
    "- `Founded`: Year in which university (or a predecessor institution) was founded\n",
    "- `Students`: Total number of students\n",
    "- `Staff`: Number of academic staff\n",
    "- `Admin`: Number of administrative staff\n",
    "- `Budget`: Budget in million pounds\n",
    "- `Russell`: Binary indicator whether university is a member of the Russell Group, an association of the UKâ€™s top research universities.\n",
    "\n",
    "The data was compiled based on information from Wikipedia.\n",
    "\n",
    "We read in the data stored in the file `universities.csv` like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know what are columns are called, we can use the `columns` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very similiar to how we already know to read in files, except it is built to read in CSVs as `DataFrames`. Now we can take a look at the first and last rows of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly compute some descriptive statistics for the *numerical* variables in the `DataFrame`, we use `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this automatically ignores the columns `Institution` and `Country` as they contain strings,\n",
    "and computing the mean, etc. of a string variable does not make sense.\n",
    "\n",
    "To see low-level information about the data type used in each column, we call `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas automatically discards missing information in computations. For example, the number of\n",
    "academic staff is missing for several universities, so the number of non-null entries reported in the table\n",
    "above is less than 23, the overall sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What questions do you want to answer?\n",
    "\n",
    "Thinking about the dataset we just imported, what questions can we ask? What information would we want to know from this dataset? What questions can this dataset help us answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the avg student to staff ratio\n",
    "- Funding of Newest or oldest institution\n",
    "- Avg year a Russell group college was founded vs non-Russell\n",
    "- Vowels in name vs funding\n",
    "- How many universities are in England, Scotland, Wales, Northern Ireland\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "Pandas supports two types of indexing:\n",
    "1. Indexing by position. This is basically identical to the indexing of other Python and NumPy options.\n",
    "2. Indexing by label, i.e., by the values assigned to the row or column index. These labels need not\n",
    "be integers in increasing order, as is the case for NumPy. We will see how to assign labels below.\n",
    "\n",
    "\n",
    "Pandas indexing is performed either by using brackets `[]`, or by using `.loc[]` for label indexing, or\n",
    "`.iloc[]` for positional indexing.\n",
    "Indexing via `[]` can be somewhat confusing:\n",
    "- specifying `df['name']` returns the column name as a Series object.\n",
    "- On the other hand, specifying a range such as `df[5:10]` returns the rows associated with the positions `5,. . . ,9.`\n",
    "\n",
    "\n",
    "Let's use our example `DataFrame` to demonstrate different ways to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas follows the Python convention that indexes start at 0, and the endpoint of a slice is not included.\n",
    "\n",
    "You can also create whole new columns using indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulated indicies\n",
    "Pandas uses *labels* to index and align data. These can be integer values starting at 0 with increments\n",
    "of 1 for each additional element, which is the default, but they need not be. The two main methods to\n",
    "manipulate indices are:\n",
    "- `set_index(keys=['column1', ...])`: uses the values of column1 and optionally additional columns as indices, discarding the current index.\n",
    "- `reset_index()`: resets the index to its default value, a sequence of increasing integers startingat 0.\n",
    "Both methods return a new `DataFrame` and leave the original `DataFrame` unchanged. If we want to\n",
    "change the existing `DataFrame`, we need to pass the argument `inplace=True`.\n",
    "\n",
    "If we want to know what our indices currently are we can use the `index` attribute, just like `Series` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, right now the indices of the `DataFrame` are the numbers 0, 1,..., 22\n",
    "\n",
    "We can replace the row index and use the lowercase Roman characters `a, b, c,...` as labels\n",
    "instead of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we changed our index from numbers to letters, we can get certain rows using our new indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add to the confusion, note that when specifying a range in terms of labels, the last element *is* included!\n",
    "Hence the row with index `c` in the above example is shown.\n",
    "\n",
    "We can reset the index to its default integer values using the `reset_index()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually keep the indices as numbers because we often have more than 26 records in our `DataFrame`(as the programmer you would have to decide what comes after `z`: `aa`? `A`?), but theoretically you could use any string you wanted as an index. \n",
    "\n",
    "\n",
    "Pandas also has other specialty index types like `DatetimeIndex` and `TimedeltaIndex` that can be really useful for standardizing data with dates and times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generally speaking, when you are talking about indexing you are refering to the columns of a DataFrame. When you are talking about slicing, you are refering to rows.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting elements\n",
    "To more clearly distinguish between selection by label and by position, pandas provides the `.loc[]`\n",
    "and `.iloc[]` methods of indexing. To make your intention obvious, you should therefore adhere to the\n",
    "following rules:\n",
    "1. Use `df['name']` only to select columns and nothing else.\n",
    "2. Use `.loc[]` to select by label.\n",
    "3. Use `.iloc[]` to select by position.\n",
    "\n",
    "\n",
    "To illustrate, using `.loc[]` indexes by label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `.loc[]` we can even perform slicing on column names, which is not possible with the simpler\n",
    "`df[]` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat surprisingly, we can include boolean statements in `.loc[]` even though these are clearly not\n",
    "labels. Here, we can use`.loc` to select all rows with the \"Scotland\" in the `Country` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use other more complicated boolean operators to splice data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection by position\n",
    "Conversely, if we want to select items exclusively by their position and ignore their labels, we use `.iloc[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common DataFrame routines\n",
    "Using `DataFrame` we can compute many common statisical calculations and database refactoring routines.\n",
    "\n",
    "\n",
    "### Statistical  operations\n",
    "While `df.describe()` can be a great tool, sometimes we want to get more specific.\n",
    "\n",
    "Methods such as `mean()` are by default applied column-wise to each column. The `numeric_only=True` argument is used to discard all non-numeric columns (depending on the version of pandas, `mean()` will issue a warning otherwise).\n",
    "\n",
    "One big advantage over NumPy is that missing values (represented by `np.nan`) are automatically\n",
    "ignored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation routines\n",
    "\n",
    "Applying aggregation functions to the entire `DataFrame` is similar to what we can do with NumPy. The\n",
    "added flexibility of pandas becomes obvious once we want to apply these functions to subsets of data,\n",
    "i.e., groups, which we can define based on values or index labels.\n",
    "\n",
    "For example, we can easily group our universities by country:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `groups` is a special pandas objects which can subsequently be used to process group-specific data.\n",
    "To compute the group-wise averages, we can simply run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groups suppot column indexing: if we want to only compute the total number of students for each country in our sample, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are numerous routines to aggregate grouped data, for example:\n",
    "- `mean()`, `sum()`: averages and sums over numerical items within groups.\n",
    "- `std()`, `var()`: within-group std. dev. and variances\n",
    "- `size()`: group sizes\n",
    "- `first()`, `last()`: first and last elements in each group\n",
    "- `min()`, `max()`: minimum and maximum elements within a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the DataFrame\n",
    "When making a line graph, you want your `DataFrame` to have the x-axis values as the column index and the data points in their own column.\n",
    "\n",
    "For example, if we wanted to plot personal savings over time, our `DataFrame` could look something like this:\n",
    "\n",
    "|  index   | Savings |\n",
    "| -------- | ------- |\n",
    "| January  | $250    |\n",
    "| February | $80     |\n",
    "| March    | $420    |\n",
    "\n",
    "The months, which will become our x-axis, are the indices and the data we want to plot is in its own column, `Savings`. If we wanted to plot our spending on the same line graph, we would add another column to our `DataFrame` and fill in our spending for each month.\n",
    "\n",
    "If your `DataFrame` is flipped, you can use `df.T` to *transpose* the `DataFrame`. This function will switch the indices and the columns of the `DataFrame` and move all the data as appropriate.\n",
    "\n",
    "For example, if our `DataFrame` looked like this:\n",
    "\n",
    "| index    | January | February | March |\n",
    "| -------- | ------- | -------- | ----- |\n",
    "| Savings  | $250    | $80      | $420  |\n",
    "\n",
    "We could make it match our target `DataFrame` above using `df.T`. \n",
    "\n",
    "Since `.T` transposes the `DataFrame` every time it runs, your `DataFrame` will flip-flop between both orientations every time you run your code. You may want to put the transposing of the `DataFrame` in its own box or \"Run All\" every time.\n",
    "\n",
    "## Plotting with matplotlib\n",
    "\n",
    "To plot a line graph using `matplotlib`, you first want to `import matplotlib.pyplot as plt`.\n",
    "\n",
    "Then for each column you want to plot you can use the function `plt.plot(df.index, df[col], ...)` where  the first parameter is the x-axis(which should be the index) and the second parameter is your column of data you want to plot. \n",
    "\n",
    "You can run this function multiple times to add multiple lines to the same graph. Your final plot will not appear until you run `plt.show()`. \n",
    "\n",
    "Before you run `plt.show()`,  you may want to add other features to your graph like titles and grid lines. If you\n",
    "\n",
    "\n",
    "```\n",
    "df = df.T\n",
    "lst = ['col1', 'col2']\n",
    "for item in lst:\n",
    "\tplt.plot(df.index, df[item],marker='.')\n",
    "plt.show()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We have used the `Matplotlib` library in the past to display images as plots. Pandas itself implements some convenience wrappers around Matplotlib plotting routines which allow us to quickly inspect data stored in `DataFrames`. Alternatively, we can extract the numerical data and pass it to Matplotlibâ€™s routines manually.\n",
    "\n",
    "There are lot of different plots we can make, so let's go through some examples now.\n",
    "\n",
    "To plot each institutions' student numbers as a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use groups to get a snapshot of different statistics. \n",
    "\n",
    "Make a pie chart to show the number of universities in each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = df.groupby('Country').size()\n",
    "# groups.plot(kind='pie', autopct='%1.1f%%', startangle=140, figsize=(8,6))\n",
    "\n",
    "## If you want it a little bit prettier and show the numerical counts instead, you will likely want to use matplotlib\n",
    "# grouped = df.groupby('Country').size()\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.pie(grouped, labels=[f'{c} [{grouped[c]}]' for c in grouped.index], autopct='', startangle=140)\n",
    "# plt.axis('equal')\n",
    "# plt.title('Distribution of Countries')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since displaying the counts is difficult, maybe we want a historgram instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I wanted to make a box and whisker plot of the years each institution was founded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Founded'].plot(kind='box', vert=False, ylabel='', xlabel='Year Founded', title='Years Founded' )\n",
    "# # Again using Matplotlib\n",
    "# plt.figure(figsize=(12, 3))\n",
    "# plt.boxplot(df['Founded'], vert=False)\n",
    "# plt.xlabel('Year Founded')\n",
    "# plt.title('Years Founded')\n",
    "\n",
    "# # Calculate quartiles and median\n",
    "# quartiles = df['Founded'].quantile([0.25, 0.5, 0.75])\n",
    "# # Add labels for quartiles and endpoints\n",
    "# plt.annotate(f'Q1: {quartiles[0.25]}', xy=(quartiles[0.25], 1), xytext=(-5, -22),\n",
    "#              textcoords='offset points', fontsize=8, color='blue')\n",
    "# plt.annotate(f'Median: {quartiles[0.5]}', xy=(quartiles[0.5], 1), xytext=(-30, -22),\n",
    "#              textcoords='offset points', fontsize=8, color='blue')\n",
    "# plt.annotate(f'Q3: {quartiles[0.75]}', xy=(quartiles[0.75], 1), xytext=(-20, -22),\n",
    "#              textcoords='offset points', fontsize=8, color='blue')\n",
    "# plt.annotate(f'Min: {df[\"Founded\"].min()}', xy=(df[\"Founded\"].min(), 1), xytext=(-5, -22),\n",
    "#              textcoords='offset points', fontsize=8, color='blue')\n",
    "# plt.annotate(f'Max: {df[\"Founded\"].max()}', xy=(df[\"Founded\"].max(), 1), xytext=(-5, -22),\n",
    "#              textcoords='offset points', fontsize=8, color='blue')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are must have features of graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
